#! /usr/bin/python
# -*- coding: utf-8 -*-

import pdb
import sys

from math import log
from time import time
from itertools import permutations

from nltk.corpus import brown			#main corpus
from nltk.util import ngrams			#ngrams extractor
from nltk.probability import FreqDist	#counter (hashmap)

#########################################################
####training model######################################
#########################################################

print 'training model, using brown corpus ...'
start = time()

unicount = FreqDist(ngrams(brown.words(), 1))	#word count
bicount = FreqDist()							#bigram count
for sent in brown.sents():				#bigram count need to be done with sentences
	bigrams = ngrams(sent, 2)			#while unigram count(word count) do not need
	for bigram in bigrams:
		bicount[bigram] += 1

print 'training finished in %.2f seconds'%(time()-start)

#########################################################
####functions############################################
#########################################################

def wordprob(w):
	return float(unicount[(w, )] + 1)/(unicount.N() + unicount.B())		#lapace smoothing for p(w)

def condprob(w1, w2):		#p(w2|w1)
	lamda = 0.9				#interpolate smoothing parameter
	if bicount[(w1, w2)] == 0:
		return (1-lamda) * wordprob(w2)
	else:
		return lamda * float(bicount[(w1, w2)])/unicount[(w1, )] + (1-lamda) * wordprob(w2)

def seqprob(seq):			#log{p(w1)*p(w2|w1)*p(w3|w2)...}
	p = log(wordprob(seq[0]))
	for i in range(1, len(seq)):
		p += log(condprob(seq[i-1], seq[i]))
	return p

#########################################################
####testing##############################################
#########################################################

while 1:
	words = raw_input("Please input some words separated by blanks\n>>> ")
	if len(words) == 0:
		continue
	
	start = time()
	seq = words.split(' ')
	all_seqs = list(permutations(seq, len(seq)))
	all_probs = [seqprob(list(s)) for s in all_seqs]
	target = all_seqs[all_probs.index(max(all_probs))]
	
	print "The most proper sentence generated by these words is \n>>>",
	print ' '.join(list(target))
	print 'It takes %.2f seconds to generate this sentence\n'%(time() - start)



